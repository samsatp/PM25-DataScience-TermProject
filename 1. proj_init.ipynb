{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_proj_init.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JeabSp4r9j50"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python391jvsc74a57bd031605234de10b43ea767264d17dfb0196cf2b9da7012776efe0be49341337db4",
      "display_name": "Python 3.9.1 64-bit ('jupyterlab2.26': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1"
    },
    "metadata": {
      "interpreter": {
        "hash": "a9c2c22397b07014c1cd4f0e704763f14b6d6b76ade59c4da849259a43dd80ef"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_E9pZ6C2yDS",
        "outputId": "b3a6654a-2d71-49ce-e45e-ea02b03d0e7f"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "from util_get_data import *\n",
        "provinces = ['Khon Kaen','Chiang Mai','Chanthaburi','Bangkok','Kanchanaburi','Songkhla']\n",
        "base_url = '../'\n",
        "dest_url = './extracted/'\n",
        "\n",
        "pd.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.4'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67eTB3SZ84Mh"
      },
      "source": [
        "## Raw -> tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Khon Kaen : (26632, 1)\n",
            "Train : Chiang Mai : (26632, 1)\n",
            "Train : Chanthaburi : (26632, 1)\n",
            "Train : Bangkok : (26632, 1)\n",
            "Train : Kanchanaburi : (26632, 1)\n",
            "Train : Songkhla : (26632, 1)\n",
            "Test : Khon Kaen : (8797, 1)\n",
            "Test : Chiang Mai : (8797, 1)\n",
            "Test : Chanthaburi : (8797, 1)\n",
            "Test : Bangkok : (8797, 1)\n",
            "Test : Kanchanaburi : (8797, 1)\n",
            "Test : Songkhla : (8797, 1)\n"
          ]
        }
      ],
      "source": [
        "target = defaultdict(lambda: {})\n",
        "wind = defaultdict(lambda: {})\n",
        "temp = defaultdict(lambda: {})\n",
        "\n",
        "for subset in ['Train', 'Test']:\n",
        "    for p in provinces:\n",
        "        target_df = get_target_df(province=p, subset=subset)\n",
        "        wind_df = get_df(measure='wind', province=p, subset=subset)\n",
        "        temp_df = get_df(measure='temperature', province=p, subset=subset)\n",
        "\n",
        "        target[subset][p] = target_df.resample('H').mean()\n",
        "        wind[subset][p] = wind_df\n",
        "        temp[subset][p] = temp_df\n",
        "\n",
        "        print(f'{subset} : {p} : {target[subset][p].shape}')"
      ]
    },
    {
      "source": [
        "## Save raw extracted files"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "for subset in ['Train', 'Test']:\n",
        "    for p in provinces:\n",
        "        target[subset][p].to_csv(f'./extracted/{subset}/{p}_target.csv')\n",
        "        wind[subset][p].to_csv(f'./extracted/{subset}/{p}_wind.csv')\n",
        "        temp[subset][p].to_csv(f'./extracted/{subset}/{p}_temp.csv')\n",
        "'''"
      ]
    },
    {
      "source": [
        "## Join PM, wind, temperature"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Khon Kaen : (26632, 4)\nTrain : Chiang Mai : (26632, 4)\nTrain : Chanthaburi : (26632, 4)\nTrain : Bangkok : (26632, 4)\nTrain : Kanchanaburi : (26632, 4)\nTrain : Songkhla : (26632, 4)\nTest : Khon Kaen : (8797, 4)\nTest : Chiang Mai : (8797, 4)\nTest : Chanthaburi : (8797, 4)\nTest : Bangkok : (8797, 4)\nTest : Kanchanaburi : (8797, 4)\nTest : Songkhla : (8797, 4)\n"
          ]
        }
      ],
      "source": [
        "full_all = defaultdict(lambda: {})\n",
        "outer_join = dict(left_index=True, right_index=True, how='outer')\n",
        "left_join = dict(how='left', left_index=True, right_index=True)\n",
        "\n",
        "for subset in ['Train','Test']:\n",
        "    for p in provinces:\n",
        "        # Full timeline \n",
        "        idx = pd.date_range(target[subset][p].index[0], \n",
        "                        target[subset][p].index[-1], freq='H')\n",
        "        timeline = pd.DataFrame(index=idx)\n",
        "\n",
        "        target_full = timeline.merge(target[subset][p], **left_join)\n",
        "\n",
        "        # Join wind &temperature\n",
        "        wind_df = wind[subset][p].drop(['lat','long'],axis=1)\n",
        "        temp_df = temp[subset][p].drop(['lat','long'],axis=1)\n",
        "\n",
        "        wind_temp = pd.merge(timeline, \n",
        "                        wind_df.merge(temp_df, **outer_join), \n",
        "                        **left_join).ffill(limit=3)\n",
        "\n",
        "        \n",
        "        full = target_full.merge(wind_temp, **left_join)\n",
        "\n",
        "        ## left = left.resample('H').mean().ffill(limit=3)\n",
        "\n",
        "        # Join PM, wind, temperature\n",
        "        #full = wind_temp_full.merge(target[subset][p], **left_join)\n",
        "\n",
        "        full_all[subset][p] = full\n",
        "        print(f\"{subset} : {p} : {full.shape}\")"
      ]
    },
    {
      "source": [
        "## Save joined 3 to full-data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./full-data/Train/Khon Kaen_full.csv\n./full-data/Train/Chiang Mai_full.csv\n./full-data/Train/Chanthaburi_full.csv\n./full-data/Train/Bangkok_full.csv\n./full-data/Train/Kanchanaburi_full.csv\n./full-data/Train/Songkhla_full.csv\n./full-data/Test/Khon Kaen_full.csv\n./full-data/Test/Chiang Mai_full.csv\n./full-data/Test/Chanthaburi_full.csv\n./full-data/Test/Bangkok_full.csv\n./full-data/Test/Kanchanaburi_full.csv\n./full-data/Test/Songkhla_full.csv\n"
          ]
        }
      ],
      "source": [
        "for subset in ['Train', 'Test']:\n",
        "    for p in provinces:\n",
        "        path = f'./full-data/{subset}/{p}_full.csv'\n",
        "        if not os.path.exists(path): full_all[subset][p].to_csv(path)\n",
        "        else: print(path)"
      ]
    },
    {
      "source": [
        "# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Don't run code below. it's deprecated",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-51c58ac5f353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Don't run code below. it's deprecated\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mException\u001b[0m: Don't run code below. it's deprecated"
          ]
        }
      ],
      "source": [
        "raise Exception(\"Don't run code below. it's deprecated\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEXKm7cu6J_D"
      },
      "source": [
        "def get_target_df(target_url, subset):\n",
        "\n",
        "    if subset == 'Test':\n",
        "        return pd.read_csv(target_url, index_col=0)\n",
        "\n",
        "    with open(target_url, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i==9:\n",
        "                cols = line.strip().split(', ')\n",
        "                break\n",
        "            \n",
        "    target_df = pd.read_csv(target_url, sep='\\t', skiprows=10, header=None)\n",
        "    target_df.columns = cols\n",
        "    target_df.iloc[:,:4] = target_df.iloc[:,:4].applymap(str)\n",
        "    target_df['Date'] = pd.to_datetime(\n",
        "                                       {'year': target_df['% Year'], \n",
        "                                        'month': target_df['Month'], \n",
        "                                        'day':target_df['Day'],\n",
        "                                        'hour': target_df['UTC Hour']})\n",
        "    target_df = target_df[['Date','PM2.5']].set_index('Date')\n",
        "    return target_df.groupby('Date').mean()\n",
        "\n",
        "def get_df(url):\n",
        "    return pd.read_csv(url, parse_dates=['datetime'], index_col='datetime')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_mWIuny6bAA",
        "outputId": "6573d20c-6a9e-496b-9999-a24a840ad23e"
      },
      "source": [
        "\n",
        "\n",
        "for subset in ['Train', 'Test']:\n",
        "    if len(os.listdir(dest_url + subset)) == 0:\n",
        "        for p in provinces:\n",
        "            if p in ['Khon Kaen','Chiang Mai']:\n",
        "                p_ = p.replace(' ','_')\n",
        "                target_url = base_url+'{}/{}/{}.'.format(p,subset,p_)\n",
        "            else:\n",
        "                target_url = base_url+'{}/{}/{}.'.format(p,subset,p)\n",
        "            if subset == 'Test':\n",
        "                target_url+='csv'\n",
        "            elif subset == 'Train':\n",
        "                target_url+='txt'\n",
        "\n",
        "            wind_url = base_url+'{}/{}/3H_wind_{}.csv'.format(p,subset,p)\n",
        "            temp_url = base_url+'{}/{}/3H_temperature_{}.csv'.format(p,subset,p)\n",
        "            \n",
        "            get_target_df(target_url, subset).to_csv(dest_url+f'{subset}/'+'{}_target.csv'.format(p))\n",
        "            get_df(wind_url).to_csv(dest_url+f'{subset}/'+'{}_wind.csv'.format(p))\n",
        "            get_df(temp_url).to_csv(dest_url+f'{subset}/'+'{}_temp.csv'.format(p))\n",
        "            print('{}/{} done!!'.format(subset,p))\n",
        "    else:\n",
        "        print(f'{subset} Preprocessed!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preprocessed!\nTest Preprocessed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muurxL279BPN"
      },
      "source": [
        "## Read TRAIN tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8z9OMeu7say"
      },
      "source": [
        "temp = dict()\n",
        "wind = dict()\n",
        "target = dict()\n",
        "\n",
        "subset = 'Test'\n",
        "\n",
        "for p in provinces:\n",
        "    target[p] = pd.read_csv(dest_url+'/{}/{}_target.csv'.format(subset,p), index_col=0, parse_dates=True)\n",
        "    wind[p] = pd.read_csv(dest_url+'/{}/{}_wind.csv'.format(subset,p), parse_dates=['datetime'], index_col='datetime')\n",
        "    temp[p] = pd.read_csv(dest_url+'/{}/{}_temp.csv'.format(subset,p), parse_dates=['datetime'], index_col='datetime')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87G0Ry_E9PQp"
      },
      "source": [
        "## Joining tables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruv50hrW9jqb",
        "outputId": "0777ce47-d29d-475b-ca13-d27373ca1aeb"
      },
      "source": [
        "print(f'subset : {subset}')\n",
        "for p in provinces:\n",
        "    print(\"temp : {} : shape\".format(p),temp[p].shape)\n",
        "    print(\"wind : {} : shape\".format(p),wind[p].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subset : Test\ntemp : Khon Kaen : shape (2936, 3)\nwind : Khon Kaen : shape (2936, 4)\ntemp : Chiang Mai : shape (2936, 3)\nwind : Chiang Mai : shape (2936, 4)\ntemp : Chanthaburi : shape (2936, 3)\nwind : Chanthaburi : shape (2936, 4)\ntemp : Bangkok : shape (2936, 3)\nwind : Bangkok : shape (2936, 4)\ntemp : Kanchanaburi : shape (2936, 3)\nwind : Kanchanaburi : shape (2936, 4)\ntemp : Songkhla : shape (2936, 3)\nwind : Songkhla : shape (2935, 4)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "ข้อมูล Wind กับ Temp เป็นข้อมูลที่มี freq = 3H ซึ่งเราต้องเอาไป join กับ target ที่มี freq = H"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JnUB07Ismlu",
        "outputId": "cd7f6a07-beea-45c6-cd9c-9654bd934074"
      },
      "source": [
        "for province in provinces:\n",
        "    # ดู date_rage ของข้อมูล PM2.5 แต่ละจังหวัด\n",
        "    target_timeline = pd.date_range(target[province].index[0], target[province].index[-1], freq='H')\n",
        "\n",
        "    print(f'{province} : full timeline : {target_timeline.shape}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Khon Kaen : full timeline : (8797,)\nChiang Mai : full timeline : (8797,)\nChanthaburi : full timeline : (8797,)\nBangkok : full timeline : (8797,)\nKanchanaburi : full timeline : (8797,)\nSongkhla : full timeline : (8797,)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "แปลว่าทุกๆ Train data เริ่มและจบที่จุดเดียวกัน -> ใช้ `target_timeline` เป็นไทม์ไลน์หลัก"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8797, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "target['Bangkok'].shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyFEACpg9Noi"
      },
      "source": [
        "# Join : temperature | wind\n",
        "temp_wind_joined = dict()\n",
        "lat_long = dict()\n",
        "\n",
        "for p in provinces:\n",
        "    lat_long[p] = {'lat': temp[p]['lat'].unique()[0], 'long': temp[p]['long'].unique()[0]}\n",
        "    wind[p] = wind[p].drop(['lat','long'], axis=1)\n",
        "    temp[p] = temp[p].drop(['lat', 'long'], axis=1)\n",
        "\n",
        "    temp_wind_joined[p] = temp[p].merge(\n",
        "                            wind[p],\n",
        "                            how='left',\n",
        "                            left_index=True,\n",
        "                            right_index=True\n",
        "                        )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1M5p_pqAEin"
      },
      "source": [
        "full_data = dict()\n",
        "'''\n",
        "for province in provinces:\n",
        "    f = target[province].copy()\n",
        "    f = f.append(pd.DataFrame(index=pd.DatetimeIndex(data=['2016-03-03 07:00:00'])))\n",
        "    f = f.sort_index()\n",
        "    f = f.resample(rule='3H', closed='left', origin='start').mean()\n",
        "\n",
        "    full_data[province] = temp_wind_joined[province].merge(f, left_index=True, right_index=True)\n",
        "    full_data[province].index.name = 'Datetime'\n",
        "'''\n",
        "# Global timeline\n",
        "timeline = pd.DataFrame(index=target_timeline)\n",
        "for province in provinces:\n",
        "    # Timeline for each province\n",
        "    timeline = pd.DataFrame(index=pd.date_range(target[province].index[0], \n",
        "                                                target[province].index[0], freq='H'))\n",
        "    full_data[province] = timeline.merge(target[province],\n",
        "                                left_index=True, \n",
        "                                right_index=True,\n",
        "                                how='left')\n",
        "    print(f\"target : {province} : {full_data[province].shape}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target : Khon Kaen : (8797, 1)\ntarget : Chiang Mai : (8797, 1)\ntarget : Chanthaburi : (8797, 1)\ntarget : Bangkok : (8797, 1)\ntarget : Kanchanaburi : (8797, 1)\ntarget : Songkhla : (8797, 1)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "เตรียม target เสร็จเรียบร้อย ต่อไปจะทำการ join (temp|wind ที่ถูก resample เป็น 1H และ fill missing by `ffill`)เข้ากับ target"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "for province in provinces:\n",
        "\n",
        "    df = temp_wind_joined[province].resample('H').mean().fillna(method='ffill')\n",
        "    full_data[province] = full_data[province].merge(df, right_index=True, left_index=True, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUt8Hlw6U9c",
        "outputId": "7b932abb-575e-4bbd-c4b2-08ad228ec006"
      },
      "source": [
        "print(f'From total records : {target_timeline.shape}')\n",
        "print(full_data['Bangkok'].columns.values, end='\\n\\n')\n",
        "for province in provinces:\n",
        "    print(f'{province} : Null value : {full_data[province].isnull().sum().values}')\n",
        "    if subset == 'Test':\n",
        "        full_data[province].rename(columns={\"PM2.5(µg/m3)\":\"PM2.5\"}, inplace=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From total records : (8797,)\n['PM2.5(µg/m3)' 'Temp(C)' 'WindDir' 'Wind Speed(km/h)']\n\nKhon Kaen : Null value : [0 0 0 0]\nChiang Mai : Null value : [0 0 0 0]\nChanthaburi : Null value : [0 0 0 0]\nBangkok : Null value : [0 0 0 0]\nKanchanaburi : Null value : [0 0 0 0]\nSongkhla : Null value : [0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J8EcmHIA_z7"
      },
      "source": [
        "print(f'subset : {subset}')\n",
        "if len(os.listdir('./full-data/' + subset)) == 0:\n",
        "    for province in provinces:\n",
        "        full_data[province].to_csv(f'./full-data/{subset}/'+province+'_full.csv')\n",
        "else:\n",
        "    print('already')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subset : Test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}